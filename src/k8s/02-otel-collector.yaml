# API reference https://github.com/open-telemetry/opentelemetry-operator/blob/main/docs/api.md
# Refs for v1beta1 config: https://github.com/open-telemetry/opentelemetry-operator/issues/3011#issuecomment-2154118998
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otelcol
  namespace: opentelemetry
  labels:
    app.kubernetes.io/destination: oss-tools
spec:
  mode: statefulset
  image: otel/opentelemetry-collector-contrib:0.126.0
  serviceAccount: otelcontribcol
  targetAllocator:
    enabled: true
    serviceAccount: opentelemetry-targetallocator-sa
    prometheusCR:
      enabled: true
      podMonitorSelector: {}
      serviceMonitorSelector: {}
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
    # This ain't pretty, but it will do for now
    - name: CLUSTERNAME
      value: "gke-kepler"

  config:
    receivers:
      otlp:
        protocols:
          grpc: {}
          http: {}

      prometheus:
        config:
          scrape_configs:
           # Collector metrics
            - job_name: 'otel-collector'
              scrape_interval: 10s
              static_configs:
              - targets: [ '0.0.0.0:8888' ]

      # Collects cluster-level metrics and entity events from the Kubernetes API server
      k8s_cluster:
        node_conditions_to_report: [ Ready, MemoryPressure ]
        allocatable_types_to_report: [ cpu, memory, storage ]
        resource_attributes:
          container.id:
            enabled: false

      # This does the same thing as the Prometheus kube-state-metrics exporter
      # Reference: https://github.com/kubernetes/kube-state-metrics
      # Pulls node, pod, container, and volume metrics from the API server on a kubelet
      kubeletstats:
        collection_interval: 20s
        auth_type: "serviceAccount"
        endpoint: "https://${env:K8S_NODE_NAME}:10250"
        insecure_skip_verify: true

    processors:
      batch: {}

      # Prevent out of memory (OOM) situations on the Collector
      memory_limiter:
        check_interval: 1s
        limit_percentage: 70
        spike_limit_percentage: 30

      # Convert Prometheus metrics names to OTel metrics names
      transform/metrics:
        error_mode: ignore
        metric_statements:
          - context: datapoint
            statements:
                - set(attributes["k8s.container.name"], attributes["container_name"]) where attributes["container_name"] != nil
                - set(attributes["k8s.pod.name"], attributes["pod_name"]) where attributes["pod_name"] != nil
                - set(attributes["k8s.namespace.name"], attributes["container_namespace"]) where attributes["container_namespace"] != nil      

      # Enriches traces, logs, and metrics with k8s attributes
      # The processor automatically discovers k8s resources (pods), extracts metadata from them and adds the 
      # extracted metadata to the relevant spans, metrics and logs as resource attributes
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
    
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.cluster.uid
        pod_association:
          - sources:
            - from: resource_attribute
              name: k8s.pod.name
            - from: resource_attribute
              name: k8s.namespace.name
          - sources:
              - from: connection


      # Enriches metrics (because we put in metrics pipeline only) with k8s attributes
      k8sattributes/k8s:
        extract:
          metadata:
            - k8s.cluster.uid
            - k8s.node.name
        pod_association:
          - sources:
              - from: connection

      # Apply changes on resource attributes
      resource:
        attributes:
          - key: k8s.cluster.name
            value: ${CLUSTERNAME}
            action: insert


    exporters:
      otlp/jaeger:
        endpoint: 'otel-jaeger-collector:4317'
        tls:
          insecure: true
      debug:
        verbosity: detailed

    service:
      pipelines:
        traces:
          receivers: [ otlp ]
          processors: [ memory_limiter, k8sattributes, batch ]
          exporters: [ otlp/jaeger, debug ]
        metrics:
          receivers: [ otlp ]
          processors: [ memory_limiter, transform/metrics, k8sattributes, batch ]
          exporters: [ debug ]
        logs:
          receivers: [ otlp ]
          processors: [ memory_limiter, k8sattributes, batch ]
          exporters: [ debug ]

        # These pipelines are specific to our Kepler setup. We have separate pipelines so that we don't "pollute" OTel
        # data coming in from our application traces, logs, and metrics.
        metrics/prom:
          receivers: [ prometheus, k8s_cluster, kubeletstats ]
          processors: [ memory_limiter, transform/metrics, k8sattributes/k8s, batch ]
          exporters: [ debug ]
